{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import tensorflow_addons as tfa\n",
    "import pickle\n",
    "import pydot\n",
    "import graphviz\n",
    "from PIL import Image\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, Flatten, Dropout, Dense\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imutils import paths\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dim = (180, 180, 3)\n",
    "\n",
    "imgs = []\n",
    "labels = []\n",
    "\n",
    "def resizer(img_paths):\n",
    "  \"\"\"\n",
    "  모델에 사용할 수 있도록 이미지 사이즈 조정\n",
    "  \"\"\"\n",
    "  for img_path in tqdm(img_paths):\n",
    "      try:\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, (img_dim[1], img_dim[0]))\n",
    "\n",
    "        label = img_path.split(os.path.sep)[-2]\n",
    "        labels.append([label])\n",
    "\n",
    "        imgs.append(img)\n",
    "      except:\n",
    "        print(f\"error file is {img_path.split('.')[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> img counts = 21465\n"
     ]
    }
   ],
   "source": [
    "images = '/Users/cmblir/Python/Phill-Detector/Model/Multi-Classification/image/images/'\n",
    "train_img_paths = sorted(list(paths.list_images(images)))\n",
    "print(\">>> img counts =\", len(train_img_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2844/21465 [00:15<01:49, 170.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error file is png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21465/21465 [01:58<00:00, 180.52it/s]\n"
     ]
    }
   ],
   "source": [
    "resizer(train_img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = np.array(imgs, dtype= 'float32') / 255.0\n",
    "imgs_test = np.array(imgs, dtype= 'float32') / 255.0\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "enc_labels = mlb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> classes name = ['X선조영제' 'nan' '소화성궤양용제' '정신신경용제' '각성제,흥분제' '간장질환용제'\n",
      " '갑상선, 부갑상선호르몬제' '강심제' '건위소화제' '골격근이완제' '구충제' '기생성 피부질환용제' '기타의 말초신경용약'\n",
      " '기타의 비뇨생식기관 및 항문용약' '기타의 비타민제' '기타의 소화기관용약' '기타의 순환계용약'\n",
      " '기타의 신경계및 감각기관용 의약품' '기타의 알레르기용약' '기타의 외피용약' '기타의 자양강장변질제' '기타의 조제용약'\n",
      " '기타의 조직세포의 기능용의약품' '기타의 종양치료제' '기타의 중추신경용약' '기타의 항생물질제제(복합항생물질제제를 포함)'\n",
      " '기타의 혈액 및 체액용약' '기타의 호르몬제(항호르몬제를 포함)' '기타의 호흡기관용약' '기타의 화학요법제'\n",
      " '난포호르몬제 및 황체호르몬제' '뇌하수체호르몬제' '단백동화스테로이드제' '단백아미노산제제' '당뇨병용제' '동맥경화용제'\n",
      " '따로 분류되지 않고 치료를 주목적으로 하지않는 의약품' '따로 분류되지 않는 대사성 의약품' '면역혈청학적 검사용 시약'\n",
      " '모발용제(발모, 탈모, 염모, 양모제)' '무기질제제' '백신류' '부신호르몬제' '부정맥용제'\n",
      " '비뇨생식기관용제(성병예방제포함)' '비타민 A 및 D제' '비타민 B1제' '비타민 B제(비타민 B1을 제외)'\n",
      " '비타민 C 및 P제' '비타민 E 및 K제' '비타민제' '설화제' '소화기관용약' '아편알카로이드계 제제' '안과용제'\n",
      " '이뇨제' '이담제' '이비과용제' '자격요법제(비특이성면역억제제를 포함)' '자궁수축제' '자율신경제' '장기제제'\n",
      " '저함량 비타민 및 미네랄 제제' '정장제' '제산제' '종합대사성제제' '주로 곰팡이, 원충에 작용하는 것'\n",
      " '주로 그람양성, 음성균, 리케치아, 비루스에 작용하는 것' '주로 그람양성, 음성균에 작용하는 것'\n",
      " '주로 그람양성균, 리케치아, 비루스에 작용하는 것' '주로 그람양성균에 작용하는 것' '주로 그람음성균에 작용하는 것'\n",
      " '주로 항산성균에 작용하는 것' '지혈제' '진경제' '진해거담제' '진훈제' '최면진정제' '최토제, 진토제' '치과구강용약'\n",
      " '치나제' '치질용제' '칼슘제' '통풍치료제' '피임제' '하제, 완장제' '합성마약' '항결핵제' '항악성종양제' '항원충제'\n",
      " '항전간제' '항히스타민제' '해독제' '해열 진통 소염제' '혈관보강제' '혈관수축제' '혈관확장제' '혈압강하제' '혈액대용제'\n",
      " '혈액응고저지제' '호흡기관용약' '혼합비타민제(비타민AD 혼합제제를 제외)' '화농성질환용제' '효소제제' '후란계 제제']\n"
     ]
    }
   ],
   "source": [
    "print('>>> classes name =', mlb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, y_train, y_test) = train_test_split(imgs, enc_labels, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델링\n",
    "class Classifier:\n",
    "\tdef build(width, height, depth, classes):\n",
    "\t\tmodel = Sequential()\n",
    "\t\tinput_shape = (height, width, depth)\n",
    "\t\t\n",
    "\t\tmodel.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape))\n",
    "\t\tmodel.add(Activation('relu'))\n",
    "\t\tmodel.add(BatchNormalization(axis=-1))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\t\tmodel.add(Dropout(0.25))\n",
    "  \n",
    "\t\tmodel.add(Conv2D(64, (3, 3), padding='same'))\n",
    "\t\tmodel.add(Activation('relu'))\n",
    "\t\tmodel.add(BatchNormalization(axis=-1))\n",
    "\t\n",
    "\t\tmodel.add(Conv2D(64, (3, 3), padding='same'))\n",
    "\t\tmodel.add(Activation('relu'))\n",
    "\t\tmodel.add(BatchNormalization(axis=-1))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\t\tmodel.add(Dropout(0.25))\n",
    " \n",
    "\t\tmodel.add(Conv2D(128, (3, 3), padding='same'))\n",
    "\t\tmodel.add(Activation('relu'))\n",
    "\t\tmodel.add(BatchNormalization(axis=-1))\n",
    "\t\n",
    "\t\tmodel.add(Conv2D(128, (3, 3), padding='same'))\n",
    "\t\tmodel.add(Activation('relu'))\n",
    "\t\tmodel.add(BatchNormalization(axis=-1))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\t\tmodel.add(Dropout(0.25))\n",
    "        \n",
    "\t\tmodel.add(Conv2D(256, (3, 3), padding='same'))\n",
    "\t\tmodel.add(Activation('relu'))\n",
    "\t\tmodel.add(BatchNormalization(axis=-1))\n",
    "\t\n",
    "\t\tmodel.add(Conv2D(256, (3, 3), padding='same'))\n",
    "\t\tmodel.add(Activation('relu'))\n",
    "\t\tmodel.add(BatchNormalization(axis=-1))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\t\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(2048))\n",
    "\t\tmodel.add(Activation('relu'))\n",
    "\t\tmodel.add(BatchNormalization())\n",
    "\t\tmodel.add(Dropout(0.5))\n",
    "  \n",
    "\t\tmodel.add(Dense(classes))\n",
    "\t\tmodel.add(Activation('softmax'))\n",
    "\t\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-15 23:30:39.858789: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-10-15 23:30:39.860390: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# 모델 설정하기\n",
    "model = Classifier.build(\n",
    "    width=img_dim[1], height=img_dim[0], depth=img_dim[2],\n",
    "    classes=len(mlb.classes_)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, to_file='model_shapes.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 및 성능 측정하기\n",
    "model.compile(loss = CategoricalCrossentropy(from_logits=False),\n",
    "optimizer=Adam(learning_rate=1e-3, decay= 1e-3 / 200),\n",
    "metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm_callback = tfa.callbacks.TQDMProgressBar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# M! GPU 사용여부 확인\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec4f603b37a43199f9d39a91b85f547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|           0/200 ETA: ?s,  ?epochs/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11bedc240b6549f99678536f4406e679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0/537           ETA: ?s - "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "  6/537 [..............................] - ETA: 3:40 - loss: 3.6263 - accuracy: 0.0938WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1465s vs `on_train_batch_end` time: 0.2498s). Check your callbacks.\n",
      "119/537 [=====>........................] - ETA: 3:12 - loss: 3.6026 - accuracy: 0.1161"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train, batch_size = 32,\n",
    "validation_data = (X_test, y_test),\n",
    "epochs = 200, verbose = 1,\n",
    "callbacks = [tqdm_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, loss_ax = plt.subplots()\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label = 'train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label = 'val loss')\n",
    "\n",
    "acc_ax.plot(history.history['accuracy'], 'b', label = 'train accuracy')\n",
    "acc_ax.plot(history.history['val_accuracy'], 'g', label = 'valid accuracy')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 훈련 과정 시각화 (손실)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_paths = sorted(\n",
    "    list(\n",
    "        paths.list_images(\"/content/drive/Shareddrives/DVC/AI 모델/DVC 이미지/TEST_images/\")\n",
    "    )\n",
    ")\n",
    "print(\">>> test image path =\", test_image_paths)\n",
    "\n",
    "print(\">>> class index =\",  mlb.classes_)\n",
    "\n",
    "for image_path in test_image_paths:\n",
    "    test_image = cv2.imread(image_path)\n",
    "\n",
    "    test_image = cv2.resize(\n",
    "        test_image, (180, 180)\n",
    "    )\n",
    "    cv2_imshow(test_image)\n",
    "\n",
    "    test_image = test_image.astype(\"float\") / 255.0\n",
    "    test_image = np.expand_dims(test_image, axis=0)\n",
    "\n",
    "    proba = model.predict(test_image)[0]\n",
    "    print(\n",
    "        np.round(proba, 3)\n",
    "    )\n",
    "    idx = np.argmax(proba)\n",
    "    print(\">>> predict class =\", mlb.classes_[idx])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c07128d27ce1dd4a88a803d950707004e45e0ff8959c893c50660bab634194b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
